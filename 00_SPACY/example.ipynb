{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import textacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "fileR = open(\"try.txt\", 'rb+')\n",
    "corpus = fileR.read()\n",
    "\n",
    "\n",
    "# patterns = [{\"POS\": \"AUX\"}, {\"POS\": \"VERB\"}]\n",
    "\n",
    "# about_talk_doc = textacy.make_spacy_doc(corpus.__str__(), lang=\"en_core_web_sm\")\n",
    "# verb_phrases = textacy.extract.token_matches(about_talk_doc, patterns=patterns)\n",
    "\n",
    "# for chunk in verb_phrases:\n",
    "#     print (chunk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('kettle1', 'The', 'det')\n",
      "('kettle1', 'electric', 'amod')\n",
      "('has', 'kettle1', 'nsubj')\n",
      "('has', 'has', 'ROOT')\n",
      "('panel', 'an', 'det')\n",
      "('panel', 'integrated', 'amod')\n",
      "('panel', 'illuminable2', 'compound')\n",
      "('has', 'panel', 'dobj')\n",
      "('panel', 'on', 'prep')\n",
      "('top', 'the', 'det')\n",
      "('on', 'top', 'pobj')\n",
      "('top', '\\r\\n', 'dep')\n",
      "('top', 'of', 'prep')\n",
      "('handle', 'its', 'poss')\n",
      "('of', 'handle', 'pobj')\n",
      "('has', '.', 'punct')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'kettle1': 'ORG', 'illuminable2': 'ORG'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc = nlp(corpus.decode())\n",
    "for token in doc:\n",
    "    print((token.head.text, token.text, token.dep_))\n",
    "\n",
    "sentence_spans = list(doc.sents)\n",
    "# displacy.serve(sentence_spans, style=\"dep\", jupyter=True)\n",
    "\n",
    "# displacy.render(doc, style='dep', jupyter=True)\n",
    "\n",
    "[(x.orth_,x.pos_, x.lemma_) for x in [y \n",
    "                                      for y\n",
    "                                      in doc \n",
    "                                      if not y.is_stop and y.pos_ != 'PUNCT']]\n",
    "\n",
    "\n",
    "\n",
    "dict([(str(x), x.label_) for x in doc.ents])\n",
    "\n",
    "#print([(x, x.ent_iob_, x.ent_type_) for x in corpus.decode()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('European', 'JJ'),\n",
       " ('authorities', 'NNS'),\n",
       " ('fined', 'VBD'),\n",
       " ('Google', 'NNP'),\n",
       " ('a', 'DT'),\n",
       " ('record', 'NN'),\n",
       " ('$', '$'),\n",
       " ('5.1', 'CD'),\n",
       " ('billion', 'CD'),\n",
       " ('on', 'IN'),\n",
       " ('Wednesday', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('abusing', 'VBG'),\n",
       " ('its', 'PRP$'),\n",
       " ('power', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('mobile', 'JJ'),\n",
       " ('phone', 'NN'),\n",
       " ('market', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('ordered', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('company', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('alter', 'VB'),\n",
       " ('its', 'PRP$'),\n",
       " ('practices', 'NNS')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "ex = 'European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices'\n",
    "\n",
    "def preprocess(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent\n",
    "\n",
    "\n",
    "sent = preprocess(ex)\n",
    "sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('European', 'NORP'), ('Google', 'ORG'), ('$5.1 billion', 'MONEY'), ('Wednesday', 'DATE')]\n",
      "[(European, 'B', 'NORP'), (authorities, 'O', ''), (fined, 'O', ''), (Google, 'B', 'ORG'), (a, 'O', ''), (record, 'O', ''), ($, 'B', 'MONEY'), (5.1, 'I', 'MONEY'), (billion, 'I', 'MONEY'), (on, 'O', ''), (Wednesday, 'B', 'DATE'), (for, 'O', ''), (abusing, 'O', ''), (its, 'O', ''), (power, 'O', ''), (in, 'O', ''), (the, 'O', ''), (mobile, 'O', ''), (phone, 'O', ''), (market, 'O', ''), (and, 'O', ''), (ordered, 'O', ''), (the, 'O', ''), (company, 'O', ''), (to, 'O', ''), (alter, 'O', ''), (its, 'O', ''), (practices, 'O', '')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "doc = nlp('European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices')\n",
    "print([(X.text, X.label_) for X in doc.ents])\n",
    "\n",
    "print([(X, X.ent_iob_, X.ent_type_) for X in doc])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
